{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWPXpfBeP6tC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import scipy.io.wavfile as wav\n",
        "import os\n",
        "import math\n",
        "from scipy.fftpack import dct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcF6jsI5QqYU"
      },
      "source": [
        "### Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSM_vGkDQNQj",
        "outputId": "a86a10fc-95a2-4a16-cc39-5628c69e60a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/cli.py\", line 68, in main\n",
            "    out = args.func(**command_args)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1734, in dataset_download_cli\n",
            "    with self.build_kaggle_client() as kaggle:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n",
            "    username=self.config_values['username'],\n",
            "             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'username'\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download mohammedabdeldayem/the-fake-or-real-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "uA67BelDQu3G",
        "outputId": "80acee1f-00ab-4030-95d0-d6de398fcf56"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'the-fake-or-real-dataset.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-69a816bb2fbe>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'the-fake-or-real-dataset.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzipObj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m    \u001b[0mzipObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'the-fake-or-real-dataset.zip'"
          ]
        }
      ],
      "source": [
        "with ZipFile('the-fake-or-real-dataset.zip', 'r') as zipObj:\n",
        "   zipObj.extractall()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8-VzNsYTG9l"
      },
      "source": [
        "### We are using 2 sec data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgFeVh-mTkfz"
      },
      "source": [
        "### Reading and collecting data from WAV files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfUlsgKDRI5F"
      },
      "outputs": [],
      "source": [
        "def read_wav(file_path):\n",
        "    rate, signal = wav.read(file_path)\n",
        "    return rate, signal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ue0st6aRTuHZ"
      },
      "source": [
        "### Pre-emphasis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mY5GJd_iTvrr"
      },
      "outputs": [],
      "source": [
        "def pre_emphasis(signal, coeff=0.97):\n",
        "    return np.append(signal[0], signal[1:] - coeff * signal[:-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrnYL7iYTxTJ"
      },
      "source": [
        "### Framing and Windowing to reduce Spectral Leaks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jZdxQYsTw0h"
      },
      "outputs": [],
      "source": [
        "def framing(signal, frame_size, hop_size, sample_rate):\n",
        "    frame_length = int(sample_rate * frame_size)\n",
        "    hop_length = int(sample_rate * hop_size)\n",
        "    frames = []\n",
        "\n",
        "    for start in range(0, len(signal) - frame_length, hop_length):\n",
        "        frames.append(signal[start:start + frame_length])\n",
        "\n",
        "    frames = np.array(frames)\n",
        "    return frames\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyeUnWG1T7Vy"
      },
      "source": [
        "### FFT to convert from Time Scale to Frequency Domain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MFHct6lUA7H"
      },
      "outputs": [],
      "source": [
        "def fft_frames(frames, sample_rate):\n",
        "    nfft = 512\n",
        "    spectrum = np.fft.rfft(frames, n=nfft)\n",
        "    magnitude = np.abs(spectrum)\n",
        "    return magnitude\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QWViGNLUH48"
      },
      "source": [
        "### Using Mel Spectrogram to mimic human hearing (Frequency to our hearing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9c7FCqCUMUx"
      },
      "outputs": [],
      "source": [
        "def mel_filter_bank(sample_rate, n_filters=23, nfft=512, f_min=0, f_max=None):\n",
        "    if f_max is None:\n",
        "        f_max = sample_rate // 2\n",
        "\n",
        "    mel_min = 2595 * np.log10(1 + f_min / 700)\n",
        "    mel_max = 2595 * np.log10(1 + f_max / 700)\n",
        "\n",
        "    mel_points = np.linspace(mel_min, mel_max, n_filters + 2)\n",
        "    hz_points = 700 * (10**(mel_points / 2595) - 1)\n",
        "\n",
        "    bin_points = np.floor((nfft + 1) * hz_points / sample_rate).astype(int)\n",
        "\n",
        "    filter_bank = np.zeros((n_filters, nfft // 2 + 1))\n",
        "\n",
        "    for i in range(1, n_filters + 1):\n",
        "        f_m_minus = bin_points[i - 1]\n",
        "        f_m = bin_points[i]\n",
        "        f_m_plus = bin_points[i + 1]\n",
        "\n",
        "        for j in range(f_m_minus, f_m):\n",
        "            filter_bank[i - 1, j] = (j - f_m_minus) / (f_m - f_m_minus)\n",
        "\n",
        "        for j in range(f_m, f_m_plus):\n",
        "            filter_bank[i - 1, j] = (f_m_plus - j) / (f_m_plus - f_m)\n",
        "\n",
        "    return filter_bank\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F-k7hqoUSm-"
      },
      "source": [
        "### Log Scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c104EjeDUUou"
      },
      "outputs": [],
      "source": [
        "def log_mel_spectrogram(magnitude, mel_filter_bank):\n",
        "    mel_spectrogram = np.dot(mel_filter_bank, magnitude.T)\n",
        "    mel_spectrogram = np.log(mel_spectrogram + 1e-6)  # Adding a small constant to avoid log(0)\n",
        "    return mel_spectrogram.T\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amOnPgnRUa3G"
      },
      "source": [
        "### DCT to obtain MFCCs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbFgKWsMUhOk"
      },
      "outputs": [],
      "source": [
        "def dct_transform(mel_spectrogram, n_coeffs=13):\n",
        "    return dct(mel_spectrogram, type=2, axis=-1, norm='ortho')[:, :n_coeffs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3E15WRfUkM4"
      },
      "source": [
        "### Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjMxCXuoUmIj"
      },
      "outputs": [],
      "source": [
        "def extract_mfcc(file_path, frame_size=0.025, hop_size=0.01, n_filters=23, n_coeffs=13):\n",
        "    sample_rate, signal = read_wav(file_path)\n",
        "\n",
        "    # Apply pre-emphasis\n",
        "    signal = pre_emphasis(signal)\n",
        "\n",
        "    # Framing\n",
        "    frames = framing(signal, frame_size, hop_size, sample_rate)\n",
        "\n",
        "    # Apply FFT to frames\n",
        "    magnitude = fft_frames(frames, sample_rate)\n",
        "\n",
        "    # Create Mel filter bank\n",
        "    mel_filter = mel_filter_bank(sample_rate, n_filters=n_filters)\n",
        "\n",
        "    # Apply Mel filter bank to the magnitude\n",
        "    mel_spectrogram = log_mel_spectrogram(magnitude, mel_filter)\n",
        "\n",
        "    # Apply DCT to get MFCCs\n",
        "    mfcc = dct_transform(mel_spectrogram, n_coeffs)\n",
        "\n",
        "    return mfcc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbztiOljUqMf"
      },
      "source": [
        "### Extract Features from Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jTU8VYzU18E"
      },
      "outputs": [],
      "source": [
        "def extract_features_from_folder(folder_path):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    for label in os.listdir(folder_path):\n",
        "        label_path = os.path.join(folder_path, label)\n",
        "        if os.path.isdir(label_path):\n",
        "            for audio_file in os.listdir(label_path):\n",
        "                if audio_file.endswith('.wav'):\n",
        "                    file_path = os.path.join(label_path, audio_file)\n",
        "                    mfcc = extract_mfcc(file_path)\n",
        "                    features.append(np.mean(mfcc, axis=0))\n",
        "                    labels.append(label)\n",
        "\n",
        "    return np.array(features), np.array(labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jskQdC0VB5C"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTkNKPmrVC0D"
      },
      "outputs": [],
      "source": [
        "def load_data(dataset_path):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    for category in ['training', 'testing', 'validation']:\n",
        "        for label, subfolder in zip([1, 0], ['real', 'fake']):\n",
        "            folder_path = os.path.join(dataset_path, category, subfolder)\n",
        "\n",
        "            for filename in os.listdir(folder_path):\n",
        "                if filename.endswith('.wav'):\n",
        "                    file_path = os.path.join(folder_path, filename)\n",
        "                    mfcc = extract_mfcc(file_path)\n",
        "\n",
        "                    features.append(mfcc)\n",
        "                    labels.append(label)  # 1 for real, 0 for fake\n",
        "\n",
        "    return np.array(features), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBF5kjfrVi4-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "9fbb0534-81ca-4458-fb11-d37eae893b8f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/for-2sec/for-2seconds/training/real'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6d95fe9ee8b1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/for-2sec/for-2seconds'\u001b[0m  \u001b[0;31m# Replace with your actual path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-17bf26dde341>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(dataset_path)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mfolder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/for-2sec/for-2seconds/training/real'"
          ]
        }
      ],
      "source": [
        "dataset_path = '/content/for-2sec/for-2seconds'  # Replace with your actual path\n",
        "X, y = load_data(dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcIPShPBXHbb"
      },
      "source": [
        "### 17870 -> Samples, 198 -> Frames per Sample, 13 -> MFCCs in each Sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dqPizz3FVujr",
        "outputId": "d4f30b16-fb77-4ec5-b3d7-0de40bd2ff10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((17870, 198, 13), (17870,))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUcVGypzXlPn"
      },
      "source": [
        "### Since SVM requires a 2-D array, X has to be reshaped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EsHG6N6jW19R",
        "outputId": "4aaf94aa-6860-447e-f5db-ef5e0c7ac2cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(17870, 2574)\n"
          ]
        }
      ],
      "source": [
        "X_reshaped = X.reshape(X.shape[0], -1)\n",
        "print(X_reshaped.shape)  # This will print (17870, 198 * 13) = (17870, 2574)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7zWuJogX0tI"
      },
      "source": [
        "### Training and Testing Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EXT5z9ACXvaw"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0w3sUKVYV6l"
      },
      "source": [
        "### Scaling to Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTJjk8iAYNPx"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVA3ADFoYkP6"
      },
      "source": [
        "### Basic SVM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyHgp2-7RJGZ"
      },
      "outputs": [],
      "source": [
        "svm = SVC(kernel='linear')\n",
        "svm.fit(X_train[:100], y_train[:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fyul11WdYnbW"
      },
      "outputs": [],
      "source": [
        "y_pred = svm.predict(X_test[:30])\n",
        "accuracy = a[ccuracy_score(y_test[:30], y_pred)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeGknDU2Yvb6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNGzthzmYdN6"
      },
      "outputs": [],
      "source": [
        "svm = SVC(kernel='linear')\n",
        "svm.fit(X_train, y_train)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}